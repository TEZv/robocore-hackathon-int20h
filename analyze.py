import os
import json
import time
import google.generativeai as genai
from dotenv import load_dotenv

# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑–º—ñ–Ω–Ω—ñ –æ—Ç–æ—á–µ–Ω–Ω—è (API –∫–ª—é—á)
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    raise ValueError("‚ùå –ü–æ–º–∏–ª–∫–∞: –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ GEMINI_API_KEY —É —Ñ–∞–π–ª—ñ .env!")

# –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ API
genai.configure(api_key=API_KEY)

# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ 2.5 Flash, –±–æ –≤—ñ–Ω —à–≤–∏–¥–∫–∏–π —ñ –ø—ñ–¥—Ç—Ä–∏–º—É—î JSON
MODEL_ID = "gemini-2.5-flash"

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó (–∂–æ—Ä—Å—Ç–∫–æ –≤–∏–º–∞–≥–∞—î–º–æ JSON)
generation_config = genai.GenerationConfig(
    temperature=0.1,  # –ù–∏–∑—å–∫–∞ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: –º–µ–Ω—à–µ –∫—Ä–µ–∞—Ç–∏–≤—É, –±—ñ–ª—å—à–µ —Å—É—Ö–æ—ó –∞–Ω–∞–ª—ñ—Ç–∏–∫–∏
    response_mime_type="application/json"
)

model = genai.GenerativeModel(
    model_name=MODEL_ID,
    generation_config=generation_config
)

# –ü—Ä–æ–º–ø—Ç –¥–ª—è —Ä–æ–ª—ñ –∞–Ω–∞–ª—ñ—Ç–∏–∫–∞
SYSTEM_PROMPT = """
–¢–∏ ‚Äî Senior Data Analyst —É –≤—ñ–¥–¥—ñ–ª—ñ –∫–æ–Ω—Ç—Ä–æ–ª—é —è–∫–æ—Å—Ç—ñ (QA) —Å–ª—É–∂–±–∏ –ø—ñ–¥—Ç—Ä–∏–º–∫–∏.
–¢–≤–æ—î –∑–∞–≤–¥–∞–Ω–Ω—è: –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –º–∞—Å–∏–≤ –¥—ñ–∞–ª–æ–≥—ñ–≤ —ñ –ø–æ–≤–µ—Ä–Ω—É—Ç–∏ –≤–∏–∫–ª—é—á–Ω–æ –≤–∞–ª—ñ–¥–Ω–∏–π JSON.

–î–ª—è –∫–æ–∂–Ω–æ–≥–æ –¥—ñ–∞–ª–æ–≥—É –≤–∏–∑–Ω–∞—á:
1. "intent" (–∫–∞—Ç–µ–≥–æ—Ä—ñ—è –ø—Ä–æ–±–ª–µ–º–∏): payment_issue, tech_error, account_access, tariff_question, refund, other.
2. "satisfaction" (–∑–∞–¥–æ–≤–æ–ª–µ–Ω—ñ—Å—Ç—å –∫–ª—ñ—î–Ω—Ç–∞ –≤ –∫—ñ–Ω—Ü—ñ): satisfied, neutral, unsatisfied.
3. "score" (–æ—Ü—ñ–Ω–∫–∞ —Ä–æ–±–æ—Ç–∏ –∞–≥–µ–Ω—Ç–∞ –≤—ñ–¥ 1 –¥–æ 5).
4. "agent_errors" (–º–∞—Å–∏–≤ –ø–æ–º–∏–ª–æ–∫ –∞–≥–µ–Ω—Ç–∞, —è–∫—â–æ —î): rude_tone, ignored_question, slow_response, false_info, none.
5. "summary" (–∫–æ—Ä–æ—Ç–∫–µ –ø–æ—è—Å–Ω–µ–Ω–Ω—è –æ—Ü—ñ–Ω–∫–∏ 1-2 —Ä–µ—á–µ–Ω–Ω—è–º–∏).

–§–æ—Ä–º–∞—Ç –≤–∏–≤–æ–¥—É ‚Äî –º–∞—Å–∏–≤ –æ–±'—î–∫—Ç—ñ–≤:
[
  {
    "dialogue_id": "ID_–¥—ñ–∞–ª–æ–≥—É",
    "intent": "...",
    "satisfaction": "...",
    "score": 5,
    "agent_errors": ["none"],
    "summary": "..."
  }
]
"""


def analyze_batch_with_retry(batch_dialogues, retries=3):
    """–í—ñ–¥–ø—Ä–∞–≤–ª—è—î –ø–∞–∫–µ—Ç –¥—ñ–∞–ª–æ–≥—ñ–≤ –Ω–∞ –∞–Ω–∞–ª—ñ–∑ –∑ –º–µ—Ö–∞–Ω—ñ–∑–º–æ–º –ø–æ–≤—Ç–æ—Ä–Ω–∏—Ö —Å–ø—Ä–æ–±"""
    prompt = SYSTEM_PROMPT + f"\n\n–û—Å—å –º–∞—Å–∏–≤ –¥—ñ–∞–ª–æ–≥—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É (—É —Ñ–æ—Ä–º–∞—Ç—ñ JSON):\n{json.dumps(batch_dialogues, ensure_ascii=False, indent=2)}"

    for attempt in range(retries):
        try:
            print(f"  –í—ñ–¥–ø—Ä–∞–≤–ª—è—é –∑–∞–ø–∏—Ç –¥–æ Gemini (—Å–ø—Ä–æ–±–∞ {attempt + 1})...")
            response = model.generate_content(prompt)

            # –ü–∞—Ä—Å–∏–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å, —â–æ–± –ø–µ—Ä–µ–∫–æ–Ω–∞—Ç–∏—Å—è, —â–æ —Ü–µ –≤–∞–ª—ñ–¥–Ω–∏–π JSON
            result_json = json.loads(response.text)
            return result_json

        except Exception as e:
            print(f"  ‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –Ω–∞ —Å–ø—Ä–æ–±—ñ {attempt + 1}: {e}")
            if attempt < retries - 1:
                print("  ‚è≥ –ß–µ–∫–∞—é 5 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ—é —Å–ø—Ä–æ–±–æ—é...")
                time.sleep(5)
            else:
                print("  ‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –ø–∞–∫–µ—Ç –ø—ñ—Å–ª—è –≤—Å—ñ—Ö —Å–ø—Ä–æ–±.")
                return None


def main():
    input_file = "dataset.json"
    output_file = "results.json"

    # –î–ª—è –∞–Ω–∞–ª—ñ–∑—É –º–æ–∂–Ω–∞ –∑–∞–ª–∏—à–∏—Ç–∏ BATCH_SIZE = 20,
    # –±–æ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä—É—î –º–∞–ª–æ —Ç–µ–∫—Å—Ç—É —É –≤—ñ–¥–ø–æ–≤—ñ–¥—å (–ª–∏—à–µ –æ—Ü—ñ–Ω–∫–∏)
    batch_size = 20

    print(f"üìÇ –ß–∏—Ç–∞—é {input_file}...")
    try:
        with open(input_file, "r", encoding="utf-8") as f:
            dataset = json.load(f)
    except FileNotFoundError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –§–∞–π–ª {input_file} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ!")
        return

    # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ dict –Ω–∞ list –¥–ª—è –∑—Ä—É—á–Ω–æ—ó –ø–∞–∫–µ—Ç–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏
    dialogues_list = [{"dialogue_id": k, "messages": v} for k, v in dataset.items()]
    total_dialogues = len(dialogues_list)

    print(f"üîç –ü–æ—á–∏–Ω–∞—î–º–æ –ü–ê–ö–ï–¢–ù–ò–ô –∞–Ω–∞–ª—ñ–∑ {total_dialogues} –¥—ñ–∞–ª–æ–≥—ñ–≤...\n")

    all_results = {}

    for i in range(0, total_dialogues, batch_size):
        batch = dialogues_list[i:i + batch_size]
        current_batch_num = (i // batch_size) + 1
        total_batches = (total_dialogues + batch_size - 1) // batch_size

        print(
            f"üì¶ –û–±—Ä–æ–±–∫–∞ –ø–∞–∫–µ—Ç—É {current_batch_num}/{total_batches} (–î—ñ–∞–ª–æ–≥–∏ {i + 1} - {min(i + batch_size, total_dialogues)})...")

        batch_result = analyze_batch_with_retry(batch)

        if batch_result:
            for item in batch_result:
                # –ó–±–∏—Ä–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –Ω–∞–∑–∞–¥ —É —Å–ª–æ–≤–Ω–∏–∫ –ø–æ dialogue_id
                d_id = item.pop("dialogue_id", "unknown_id")
                all_results[d_id] = item

                # –ö—Ä–∞—Å–∏–≤–∏–π –≤–∏—Å–Ω–æ–≤–æ–∫ —É –∫–æ–Ω—Å–æ–ª—å
                icon = "‚úÖ" if item.get("score", 0) >= 4 else ("‚ö†Ô∏è" if item.get("score", 0) == 3 else "‚ùå")
                print(
                    f"  {icon} {d_id} -> Intent: {item.get('intent')} | –ó–∞–¥–æ–≤–æ–ª–µ–Ω—ñ—Å—Ç—å: {item.get('satisfaction')} | –û—Ü—ñ–Ω–∫–∞: {item.get('score')}/5")

        # –ü–∞—É–∑–∞ –º—ñ–∂ –ø–∞–∫–µ—Ç–∞–º–∏ –¥–ª—è –æ–±—Ö–æ–¥—É Rate Limits
        if i + batch_size < total_dialogues:
            print("  ‚è≥ –ü–∞—É–∑–∞ 10 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –Ω–∞—Å—Ç—É–ø–Ω–∏–º –ø–∞–∫–µ—Ç–æ–º...")
            time.sleep(10)

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(all_results, f, ensure_ascii=False, indent=4)

    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ ‚Üí {output_file}")


if __name__ == "__main__":
    main()